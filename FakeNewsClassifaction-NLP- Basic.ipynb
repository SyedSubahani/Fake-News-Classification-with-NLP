{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12aff47a",
   "metadata": {},
   "source": [
    "\n",
    "# Problem Statement :\n",
    "## Fake News Classification with The Help Of Natural Language Processing Technique.\n",
    "Fake news detection is a hot topic in the field of natural language processing. We consume news through several mediums throughout the day in our daily routine, but sometimes it becomes difficult to decide which one is fake and which one is authentic. Our job is to create a model which predicts whether a given news is real or fake.\n",
    "\n",
    "## Dataset Description\n",
    "\n",
    "id: unique id for a news article\n",
    "\n",
    "title: the title of a news article\n",
    "\n",
    "author: author of the news article\n",
    "\n",
    "text: the text of the article; could be incomplete\n",
    "\n",
    "label: a label that marks the article as potentially unreliable\n",
    "\n",
    "  1: unreliable\n",
    "  \n",
    "  0: reliable\n",
    " \n",
    " ### Data Collection\n",
    "- Dataset Source - https://zenodo.org/record/4561253/files/WELFake_Dataset.csv?download=1\n",
    "- The data consists of 5 column and 20800 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8944078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer,CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from tqdm import tqdm # printing the status bar\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.pandas.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09189df",
   "metadata": {},
   "source": [
    "### 1. Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eca272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/News_dataset.csv\")\n",
    "\n",
    "print(\"Shape: \", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51f8d3c",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Data Checks to perform\n",
    "\n",
    "- Check Missing values\n",
    "- Check Duplicates\n",
    "- Check data type\n",
    "- Check the number of unique values of each column\n",
    "- Check statistics of data set\n",
    "- Check various categories present in the different categorical column\n",
    "\n",
    "### 2.1 Check Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332d4b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a34674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.isna().sum()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0062de2",
   "metadata": {},
   "source": [
    "<b>Observation:</b>  There are missing values in the given dataset\n",
    "- 558 titles features are missing\n",
    "- 1957 author details are missing\n",
    "- 39 text features are missing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f30b316",
   "metadata": {},
   "source": [
    "### 2.2 Check duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac04866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33bfabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duplicate values Features wise:\")\n",
    "#print(\"Title: \", df[\"title\"].duplicated().sum())\n",
    "#print(\"Author: \", df[\"author\"].duplicated().sum())\n",
    "print(\"text: \", df[\"text\"].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2136df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"text\"].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6e9015",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check the percentage of null values present in each feature\n",
    "feature_na =[feature for feature in df.columns if df[feature].isnull().sum() > 0]\n",
    "\n",
    "for feature in feature_na:\n",
    "    print(feature, np.round(df[feature].isnull().mean(),4)*100, \" % missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd81acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_na = df[df[\"text\"].isnull()]\n",
    "# Deleteting the rows where text features is null\n",
    "df.drop(df[df[\"text\"].isnull()].index, inplace = True, axis=0)\n",
    "df.drop(df[df[\"id\"].isnull()].index, inplace = True, axis=0)\n",
    "#Update the other features null values with \"missing\"\n",
    "df[\"title\"].fillna(\"missing\", inplace=True)\n",
    "df[\"author\"].fillna(\"missing\", inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d5953",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddafa8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting data according to text in ascending order\n",
    "sorted_data=df.sort_values('text', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0890944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data[sorted_data[\"text\"].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f78f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many positive and negative reviews are present in our dataset?\n",
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d3631",
   "metadata": {},
   "source": [
    "# 3.  Text Preprocessing.\n",
    "\n",
    "Now that we have finished deduplication our data requires some preprocessing before we go on further with analysis and making the prediction model.\n",
    "\n",
    "Hence in the Preprocessing phase we do the following in the order below:-\n",
    "\n",
    "1. Begin by removing the html tags\n",
    "2. Remove any punctuations or limited set of special characters like , or . or # etc.\n",
    "3. Check if the word is made up of english letters and is not alpha-numeric\n",
    "4. Check to see if the length of the word is greater than 2 (as it was researched that there is no adjective in 2-letters)\n",
    "5. Convert the word to lowercase\n",
    "6. Remove Stopwords\n",
    "7. Finally Snowball Stemming the word (it was obsereved to be better than Porter Stemming)<br>\n",
    "\n",
    "After which we collect the words used to describe positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fbcf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/sebleier/554280\n",
    "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
    "# <br /><br /> ==> after the above steps, we are getting \"br br\"\n",
    "# we are including them into stop words list\n",
    "# instead of <br /> if we have <br/> these tags would have revmoved in the 1st step\n",
    "\n",
    "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74549de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(corpus):\n",
    "    preprocessed = []\n",
    "    for sentance in tqdm(corpus):\n",
    "        #sentance = re.sub(r\"http+\", \"\", sentance)\n",
    "        sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
    "        sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
    "        sentance = decontracted(sentance)\n",
    "        sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
    "        sentance = re.sub('[^A-Za-z]+', ' ', sentance)    \n",
    "        sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
    "        preprocessed.append(sentance.strip())\n",
    "\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e739ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "lm = WordNetLemmatizer()\n",
    "corpus = []\n",
    "for i in range (len(df)):\n",
    "    review = re.sub('^a-zA-Z0-9',' ', df['title'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lm.lemmatize(x) for x in review if x not in stopwords]\n",
    "    review = \" \".join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bbcd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474e30b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessed_text = preprocess(df['text'].values)\n",
    "preprocessed_title = preprocess(df['title'].values)\n",
    "#preprocessed_author = preprocess(df['author'].values)\n",
    "\n",
    "#print(preprocessed_text[1500])\n",
    "#print(preprocessed_title[1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410722a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = preprocessed_text\n",
    "#df[\"title\"] = preprocessed_title\n",
    "#df[\"author\"] = preprocessed_author\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43a2705",
   "metadata": {},
   "source": [
    "## 4.  Vectorization (Convert Text data into the Vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e7eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer()\n",
    "#X = tf.fit_transform(preprocessed_text).toarray()\n",
    "X = tf.fit_transform(preprocessed_text).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0acfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5f6378",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df[\"label\"].astype(np.uint8)\n",
    "\n",
    "y = df[\"label\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559a15e0",
   "metadata": {},
   "source": [
    "## Data splitting into the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9300da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 10, stratify = y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f9dc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_Train Shape:\", X_train.shape)\n",
    "print(\"X_test Shape:\", X_test.shape)\n",
    "print(\"y_train Shape:\", y_train.shape)\n",
    "print(\"y_test Shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a33aaac",
   "metadata": {},
   "source": [
    "## Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb115fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = list()\n",
    "resample = list()\n",
    "precision = list()\n",
    "recall = list()\n",
    "F1score = list()\n",
    "AUCROC = list()\n",
    "\n",
    "def test_eval(clf_model, X_test, y_test, algo=None, sampling=None):\n",
    "    # Test set prediction\n",
    "    y_prob=clf_model.predict_proba(X_test)\n",
    "    y_pred=clf_model.predict(X_test)\n",
    "\n",
    "    print('Confusion Matrix')\n",
    "    print('*'*60)\n",
    "    print(confusion_matrix(y_test,y_pred),\"\\n\")\n",
    "    print('Classification Report')\n",
    "    print('*'*60)\n",
    "    print(classification_report(y_test,y_pred),\"\\n\")\n",
    "   \n",
    "          \n",
    "    model.append(algo)\n",
    "    precision.append(precision_score(y_test,y_pred))\n",
    "    recall.append(recall_score(y_test,y_pred))\n",
    "    F1score.append(f1_score(y_test,y_pred))\n",
    "    AUCROC.append(roc_auc_score(y_test, y_prob[:,1]))\n",
    "    resample.append(sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ef5977",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ca1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model=LogisticRegression()\n",
    "\n",
    "params={'C':np.logspace(-10, 1, 15),'class_weight':[None,'balanced'],'penalty':['l1','l2']}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=100, shuffle=True)\n",
    "\n",
    "# Create grid search using 5-fold cross validation\n",
    "clf_LR = GridSearchCV(log_model, params, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "clf_LR.fit(X_train, y_train)\n",
    "#clf_LR.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4571fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval(clf_LR, X_test, y_test, 'Logistic Regression', 'actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a9266d",
   "metadata": {},
   "source": [
    "### 2. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5610a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [2,10,30,50,100]\n",
    "# Maximum number of depth in each tree:\n",
    "max_depth = [i for i in range(5,16,2)]\n",
    "# Minimum number of samples to consider to split a node:\n",
    "min_samples_split = [2, 5, 10, 15, 20, 50, 100]\n",
    "# Minimum number of samples to consider at each leaf node:\n",
    "min_samples_leaf = [1, 2, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd4856",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier()\n",
    "\n",
    "tree_param_grid = { \n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf\n",
    "}\n",
    "\n",
    "clf_DT = RandomizedSearchCV(tree_model, tree_param_grid, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=2)\n",
    "clf_DT.fit(X_train, y_train)\n",
    "clf_DT.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ccd5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval(clf_DT, X_test, y_test, 'Decision Tree', 'actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb6ffbd",
   "metadata": {},
   "source": [
    "### 2. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb21a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_params={'n_estimators':estimators,\n",
    "           'max_depth':max_depth,\n",
    "           'min_samples_split':min_samples_split}\n",
    "\n",
    "clf_RF = RandomizedSearchCV(rf_model, rf_params, cv=cv, scoring='roc_auc', n_jobs=-1, n_iter=20, verbose=2)\n",
    "clf_RF.fit(X_train, y_train)\n",
    "clf_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f85c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval(clf_RF, X_test, y_test, 'Random Forest', 'actual')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
